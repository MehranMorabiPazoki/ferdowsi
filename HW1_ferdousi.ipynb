{"cells":[{"cell_type":"markdown","metadata":{"id":"wDahmgQGem9p"},"source":["# Prepair"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23118,"status":"ok","timestamp":1675444681714,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"IbIUd6pCFuCk","outputId":"1cc90444-c4f4-4dd5-8818-3093d063a1fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"pdWYuIDzz2TS"},"source":["Warning copy ferdousi.txt in this directory or copy form google drive form correct path!\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":723,"status":"ok","timestamp":1675444682429,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"SjIOMrT9FuCn"},"outputs":[],"source":["# !cp /content/drive/MyDrive/HW4_Q1/ferdousi.txt .\n","!cp /content/drive/MyDrive/HW4_Q1_notebook/ferdousi.txt ."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17294,"status":"ok","timestamp":1675444700316,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"BP-5Jrudn73Z","outputId":"763a7064-5a36-49f8-8e4d-b36667a7771a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n","Installing collected packages: portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.25.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.21.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.16.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.12.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"]}],"source":["!pip install datasets\n","!pip install sacrebleu\n","!pip install tensorboard\n","! pip install PersianStemmer\n","! pip install https://github.com/htaghizadeh/PersianStemmer-Python/archive/master.zip --upgrade\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675444700316,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"0R-_9DG8tBBw"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5144,"status":"ok","timestamp":1675444705454,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"xAAMKtbEFuCo"},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import datasets\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import os\n","import re\n","import random\n","import gdown\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4978,"status":"ok","timestamp":1675444710419,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"vqCLrrSHmaTj","outputId":"8471edab-3ba8-4dc8-9d04-473ac405e83c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/glove/vectors.zip\n","To: /content/vectors.zip\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.2M/48.2M [00:00<00:00, 296MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Archive:  vectors.zip\n","  inflating: vectors.txt             \n"]}],"source":["gdown.download(url=\"https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/glove/vectors.zip\",output=\"vectors.zip\")\n","!unzip \"vectors.zip\""]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194},"executionInfo":{"elapsed":8375,"status":"ok","timestamp":1675446861225,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"YO5nE3yyRs6V","outputId":"f31366b5-4794-45ac-9386-1995aaf28d34"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/word2vec-cbow/word2vec.model-cbow-size%3D200-window%3D5.part1.rar\n","To: /content/part1.rar\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99.6M/99.6M [00:00<00:00, 355MB/s]\n","Downloading...\n","From: https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/word2vec-cbow/word2vec.model-cbow-size%3D200-window%3D5.part2.rar\n","To: /content/part2.rar\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82.7M/82.7M [00:00<00:00, 221MB/s]\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'part2.rar'"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["gdown.download(url=\"https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/word2vec-cbow/word2vec.model-cbow-size%3D200-window%3D5.part1.rar\",output=\"part1.rar\")\n","gdown.download(url=\"https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/word2vec-cbow/word2vec.model-cbow-size%3D200-window%3D5.part2.rar\",output=\"part2.rar\")"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7468,"status":"ok","timestamp":1675446898010,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"DgqMINR7SuPX","outputId":"7effe55a-542b-48d4-d4e8-f1c8e5ff672e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","UNRAR 5.61 beta 1 freeware      Copyright (c) 1993-2018 Alexander Roshal\n","\n","\n","Extracting from part2.rar\n","\n","\n","Extracting from part1.rar\n","\n","Extracting  word2vec.model-cbow-size=200-window=5.bin                    \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\n","\n","Extracting from part2.rar\n","\n","...         word2vec.model-cbow-size=200-window=5.bin                    \b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n"]}],"source":["!unrar e \"part2.rar\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfRYhyavfrhR"},"outputs":[],"source":["from gensim.models.keyedvectors import KeyedVectors\n","\n","model = KeyedVectors.load_word2vec_format('/content/word2vec.model-cbow-size=200-window=5.bin', binary=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wMCKVCP3pI-I"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"FXUYdGpMFuCq"},"source":["# Data PreProcessing"]},{"cell_type":"markdown","metadata":{"id":"xegIjXECqwlF"},"source":["## initialize Lang Class"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":517,"status":"ok","timestamp":1675446132556,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"R9CGMKbXFuCs"},"outputs":[],"source":["SOS_token = 0\n","EOS_token = 1\n","PAD_token = 2\n","MAX_LENGTH = 0\n","\n","#initialize Lang Class\n","class Lang:\n","   def __init__(self):\n","       #initialize containers to hold the words and corresponding index\n","       self.word2index = {}\n","       self.word2count = {}\n","       self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\"} #\n","       self.n_words = 3  # Count SOS and EOS and PAD\n","\n","#split a sentence into words and add it to the container\n","   def addSentence(self, sentence):\n","       for word in sentence.split(' '):\n","           self.addWord(word)\n","\n","#If the word is not in the container, the word will be added to it, \n","#else, update the word counter\n","   def addWord(self, word):\n","       if word not in self.word2index:\n","           self.word2index[word] = self.n_words\n","           self.word2count[word] = 1\n","           self.index2word[self.n_words] = word\n","           self.n_words += 1\n","       else:\n","           self.word2count[word] += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_E1Z0Ztq7HM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EuGeZ-Jmq7iu"},"source":["## Parsing Dataset file "]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1096,"status":"ok","timestamp":1675446134325,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"S6F9ZwDiFuCt"},"outputs":[],"source":["def read_sentence(df, lang1, lang2):\n","   sentence1 = df[lang1]\n","   sentence2 = df[lang2]\n","   return sentence1, sentence2\n","   \n","def Word2vec(path=\"/content/vectors.txt\"):\n","  file=open(path, mode=\"r\")\n","  L=file.readlines(-1)\n","  Word_feature={}\n","  for i in L:\n","    vect=i.split()\n","    Word_feature[vect[0]]=np.array(vect[1:],dtype=float)\n","  return Word_feature\n","\n","def read_file(loc, lang1, lang2):\n","   df = pd.read_csv(loc, delimiter='\\n', header=None, names=['Beyt'])[2::]\n","   d = {lang1:df[0::2].values[:,0].tolist() , lang2: df[1::2].values[:,0].tolist()}\n","   df=pd.DataFrame(d)\n","   return df\n","\n","def process_data(lang1,lang2):\n","   global MAX_LENGTH\n","   df = read_file('ferdousi.txt', lang1, lang2)\n","   print(\"Read %s sentence pairs\" % len(df))\n","   sentence1, sentence2 = read_sentence(df, lang1, lang2)\n","  #  print(sentence1[0])\n","   source = Lang()\n","   target = Lang()\n","   pairs = []\n","\n","   for i in range(len(df)):\n","      if len(sentence1[i].split(' '))>MAX_LENGTH:\n","         MAX_LENGTH = len(sentence1[i].split(' '))\n","     \n","      full = [sentence1[i], sentence2[i]]\n","      source.addSentence(sentence1[i])\n","      target.addSentence(sentence2[i])\n","      pairs.append(full)\n","\n","   print(f\"Maximum lenght of input is {MAX_LENGTH}\")\n","\n","   return source, target, pairs"]},{"cell_type":"markdown","metadata":{"id":"xy7D_Nh3rUmV"},"source":["## try to find best Word2Vec Model and test it!!"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6634,"status":"ok","timestamp":1675452086159,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"7_mlMEoMFuCu","outputId":"5b3fa103-b69f-425c-a65a-7d2f38cee4f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Read 49609 sentence pairs\n","Maximum lenght of input is 11\n","Number of included Word from source in Word2Vec Model 6794\n","Number of excluded Word from source in Word2Vec Model 4542\n"]}],"source":["lang1 = 'M1'\n","lang2 = 'M2'\n","source, target, pairs = process_data(lang1, lang2)\n","from gensim.models.keyedvectors import KeyedVectors\n","from PersianStemmer import PersianStemmer \n","model = KeyedVectors.load_word2vec_format('/content/word2vec.model-cbow-size=200-window=5.bin', binary=True)\n","\n","\n","ps = PersianStemmer()\n","\n","x=[]\n","included=0\n","excluded=0\n","for i in source.word2index.keys():\n","  try: # search original word on Word2Vec model\n","    A=model.get_vector(i)\n","    included+=1\n","  except:\n","    try: # try to find word  after Stemmer on Word2Vec model\n","      A=model.get_vector(ps.run(i))\n","    except:\n","      x.append(i)\n","      excluded+=1\n","print(\"Number of included Word from source in Word2Vec Model\",included)\n","print(\"Number of excluded Word from source in Word2Vec Model\",excluded)\n"]},{"cell_type":"markdown","metadata":{"id":"KGS6dNB7sHEw"},"source":["after using all technique to pretrain Word2Vec these cant find about 40 precent of Words used in Shahnameh,by the way we should train new embedding model"]},{"cell_type":"markdown","metadata":{"id":"sHAUAgOSsATM"},"source":["## convert to tensor"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675446134984,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"I6XufbzrFuCw"},"outputs":[],"source":["def indexesFromSentence(lang, sentence):\n","   return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","   global PAD_token\n","   global MAX_LENGTH\n","   indexes = indexesFromSentence(lang, sentence)\n","   pad_list=[PAD_token for i in range(MAX_LENGTH-len(indexes))]\n","   indexes =  indexes  + pad_list\n","   indexes.append(EOS_token)\n","   return torch.tensor(indexes, dtype=torch.long,device=device).view(-1, 1)\n","\n","def tensorsFromPair(input_lang, output_lang, pair):\n","   input_tensor = tensorFromSentence(input_lang, pair[0])\n","   target_tensor = tensorFromSentence(output_lang, pair[1])\n","   return (input_tensor, target_tensor)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675446134984,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"1Yw3WLD_FuCx"},"outputs":[],"source":["training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n","                     for i in range(10)]\n","                     "]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675446134985,"user":{"displayName":"Mehran Pazoki","userId":"18197840649722223156"},"user_tz":-210},"id":"rk7L_RqRJJ8L","outputId":"97ab5db3-a64e-48fa-fd18-a1b73b296bef"},"outputs":[{"data":{"text/plain":["[(tensor([[  94],\n","          [  67],\n","          [ 242],\n","          [4244],\n","          [   7],\n","          [3084],\n","          [ 649],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[ 822],\n","          [ 253],\n","          [ 424],\n","          [  13],\n","          [1065],\n","          [ 161],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[1537],\n","          [ 394],\n","          [1412],\n","          [ 366],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[ 205],\n","          [ 435],\n","          [3933],\n","          [8339],\n","          [1517],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[12481],\n","          [ 1279],\n","          [  205],\n","          [ 1085],\n","          [    2],\n","          [    2],\n","          [    2],\n","          [    2],\n","          [    2],\n","          [    2],\n","          [    2],\n","          [    1]]), tensor([[1764],\n","          [1612],\n","          [5827],\n","          [ 487],\n","          [ 269],\n","          [ 410],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[2044],\n","          [ 403],\n","          [ 176],\n","          [4250],\n","          [ 846],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[ 208],\n","          [3458],\n","          [  24],\n","          [1533],\n","          [ 873],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[ 546],\n","          [ 334],\n","          [2167],\n","          [2168],\n","          [ 448],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[ 189],\n","          [3454],\n","          [ 467],\n","          [ 964],\n","          [3279],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[ 143],\n","          [ 144],\n","          [ 950],\n","          [1638],\n","          [3762],\n","          [  83],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[ 208],\n","          [ 876],\n","          [  13],\n","          [6766],\n","          [ 201],\n","          [ 752],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[3575],\n","          [3461],\n","          [   3],\n","          [ 172],\n","          [2014],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[ 298],\n","          [ 487],\n","          [1985],\n","          [ 548],\n","          [ 731],\n","          [  13],\n","          [ 265],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[  13],\n","          [2074],\n","          [   3],\n","          [3056],\n","          [ 857],\n","          [ 153],\n","          [3295],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[1620],\n","          [  24],\n","          [1491],\n","          [1231],\n","          [ 189],\n","          [1072],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[ 894],\n","          [2670],\n","          [ 135],\n","          [6465],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]]), tensor([[2801],\n","          [1038],\n","          [ 192],\n","          [1125],\n","          [  65],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   2],\n","          [   1]])), (tensor([[558],\n","          [891],\n","          [899],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  1]]), tensor([[924],\n","          [925],\n","          [627],\n","          [ 13],\n","          [731],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  2],\n","          [  1]]))]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["training_pairs"]},{"cell_type":"markdown","metadata":{"id":"BmnrWQT9FuCy"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCQ5JSxqFuCy"},"outputs":[],"source":["class Encoder(nn.Module):\n","   def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers,GRU=False):\n","       super(Encoder, self).__init__()\n","      \n","       #set the encoder input dimesion , embbed dimesion, hidden dimesion, and number of layers \n","       self.input_dim = input_dim\n","       self.embbed_dim = embbed_dim\n","       self.hidden_dim = hidden_dim\n","       self.num_layers = num_layers\n","\n","       #initialize the embedding layer with input and embbed dimention\n","       self.embedding = nn.Embedding(input_dim, self.embbed_dim,padding_idx=2) #\n","       #intialize the GRU to take the input dimetion of embbed, and output dimention of hidden and\n","       #set the number of gru layers\n","       if GRU:\n","        self.recurrent = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n","       else:\n","        self.recurrent = nn.LSTM(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n","              \n","   def forward(self, src):\n","       \n","       embedded = self.embedding(src).view(1,1,-1)\n","       outputs, hidden = self.recurrent(embedded)\n","       return outputs, hidden\n","   def initHidden(self):\n","     return torch.zeros(1, 1, self.hidden_dim, device=device)\n","\n","class Decoder(nn.Module):\n","   def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers,GRU=False):\n","       super(Decoder, self).__init__()\n","\n","#set the encoder output dimension, embed dimension, hidden dimension, and number of layers \n","       self.embbed_dim = embbed_dim\n","       self.hidden_dim = hidden_dim\n","       self.output_dim = output_dim\n","       self.num_layers = num_layers\n","\n","# initialize every layer with the appropriate dimension. For the decoder layer, it will consist of an embedding, GRU, a Linear layer and a Log softmax activation function.\n","       self.embedding = nn.Embedding(output_dim, self.embbed_dim ,padding_idx=2) # \n","       \n","       if GRU:\n","        self.recurrent = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n","       else :\n","        self.recurrent=nn.LSTM(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n","\n","       self.out = nn.Linear(self.hidden_dim, output_dim)\n","       self.softmax = nn.LogSoftmax(dim=1)\n","      \n","   def forward(self, input, hidden):\n","\n","# reshape the input to (1, batch_size)\n","       input = input.view(1, -1)\n","       embedded = F.relu(self.embedding(input))\n","       output, hidden = self.recurrent(embedded, hidden)       \n","       prediction = self.softmax(self.out(output[0]))\n","      \n","       return prediction, hidden\n","   def initHidden(self):\n","      return torch.zeros(1, 1, self.hidden_dim, device=device)\n","\n","class Seq2Seq(nn.Module):\n","   def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH,mode='GRU'):\n","       super().__init__()\n","      \n","#initialize the encoder and decoder\n","       self.encoder = encoder\n","       self.decoder = decoder\n","       self.device = device\n","       self.mode = mode\n","   def forward(self, source, target, teacher_forcing_ratio=0.5):\n","\n","       input_length = source.size(0) #get the input length (number of words in sentence)\n","       batch_size = target.shape[1] \n","       target_length = target.shape[0]\n","       vocab_size = self.decoder.output_dim\n","      \n","#initialize a variable to hold the predicted outputs\n","       outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n","\n","#encode every word in a sentence\n","       for i in range(input_length):\n","           encoder_output, encoder_hidden = self.encoder(source[i])\n","\n","#use the encoderâ€™s hidden layer as the decoder hidden\n","       \n","       if self.mode == \"GRU\":\n","         decoder_hidden = encoder_hidden.to(device)\n","       elif self.mode == \"LSTM\":\n","         decoder_hidden = (encoder_hidden[0].to(device),encoder_hidden[1].to(device))\n","       \n","#add a token before the first predicted word\n","       decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n","\n","#topk is used to get the top K value over a list\n","#predict the output word from the current target word. If we enable the teaching force,  then the #next decoder input is the next word, else, use the decoder output highest value. \n","\n","       for t in range(target_length):   \n","           decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","           outputs[t] = decoder_output\n","           teacher_force = random.random() < teacher_forcing_ratio\n","           topv, topi = decoder_output.topk(1)\n","           input = (target[t] if teacher_force else topi)\n","           if(teacher_force == False and input.item() == EOS_token):\n","               break\n","\n","       return outputs"]},{"cell_type":"markdown","metadata":{"id":"3Oj4Yc1UFuC-"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["0c64a6a50d9e4c41a5f1d7591700c859","1916a5d353a94dea80b79af06f33ce68","df3788559ea5425396b38dfa6e55c1e5","2390946e0905462894fb8c1959e42fe8","672277e98bee42e6b9c521307bb0060e","30ebee065ee64ce68dfacd1eb122f997","314094a449444440bd65e2472b7425b3","06471efb792b4cf0b4605edc272142b4","0c55ffad6a8246aa97c10d4a4e9f0c9d","d8472e955bf74dc1a43e16ec64d006f3","bad9a9f9fc6f466b97c0bca94343ae77"]},"id":"OJWRGTEDFuC-","outputId":"2b661dfc-2e48-42f3-e9b1-a6ca8f41de2a"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-22-4d2c4558e126>:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = datasets.load_metric('sacrebleu')\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c64a6a50d9e4c41a5f1d7591700c859","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["teacher_forcing_ratio = 0.5\n","import datasets\n","\n","metric = datasets.load_metric('sacrebleu')\n","\n","def clacModel(model, input_tensor, target_tensor, model_optimizer, criterion):\n","\n","   model_optimizer.zero_grad()\n","\n","   input_length = input_tensor.size(0)\n","   loss = 0\n","   epoch_loss = 0\n","   # print(input_tensor.shape)\n","\n","   output = model(input_tensor, target_tensor,teacher_forcing_ratio)\n","\n","   num_iter = output.size(0)\n","  #  print(num_iter)\n","\n","#calculate the loss from a predicted sentence with the expected result\n","   for ot in range(num_iter):\n","       loss += criterion(output[ot], target_tensor[ot])\n","       \n","   metric.add(predictions=output, references=target_tensor)\n","   \n","   loss.backward()\n","   model_optimizer.step()\n","   epoch_loss = loss.item() / num_iter\n","\n","   return epoch_loss,metric\n","\n","def trainModel(model, source, target, pairs, num_iteration=20000,type='GRU'):\n","   \n","   model.train()\n","\n","  #  optimizer = optim.SGD(model.parameters(), lr=0.01)\n","   optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\n","  #  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=num_iteration//5000,eta_min=1e-4,last_epoch=-1)\n","  #  criterion = nn.NLLLoss()\n","   criterion = nn.CrossEntropyLoss()\n","   total_loss_iterations = 0\n","   final_score = 0\n","   training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n","                     for i in range(num_iteration)]\n","  \n","   for iter in tqdm(range(1, num_iteration+1)):\n","       training_pair = training_pairs[iter - 1]\n","       input_tensor = training_pair[0]\n","       target_tensor = training_pair[1]\n","\n","       loss,metric = clacModel(model, input_tensor, target_tensor, optimizer, criterion)\n","       s  = metric.compute()\n","\n","       final_score += s['score']\n","       \n","       total_loss_iterations += loss\n","       writer.add_scalar('Loss', loss,iter)\n","       writer.add_scalar('score', s['score'],iter) \n","\n","       if iter % 5000 == 0:\n","           avarage_loss= total_loss_iterations / 5000\n","           avg_score = final_score /5000\n","           total_loss_iterations = 0\n","           tqdm.write(f'iter :{iter} , Loss : {avarage_loss} , score :{avg_score}')\n","          #  scheduler.step()\n","           torch.save(model.state_dict(), f'/content/drive/MyDrive/HW4_Q1/{type}_Model.pt')\n","          \n","   return model"]},{"cell_type":"markdown","metadata":{"id":"zm6otv8sFuC_"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gabw_5sDFuC_"},"outputs":[],"source":["def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentences[0])\n","        output_tensor = tensorFromSentence(output_lang, sentences[1])\n","\n","        decoded_words = []\n","\n","        output = model(input_tensor, output_tensor)\n","        # print(output_tensor)\n","\n","        for ot in range(output.size(0)):\n","            topv, topi = output[ot].topk(1)\n","            # print(topi)\n","\n","            if topi[0].item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi[0].item()])\n","    return decoded_words\n","\n","def evaluateRandomly(model, source, target, pairs, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('source {}'.format(pair[0]))\n","        print('target {}'.format(pair[1]))\n","        output_words = evaluate(model, source, target, pair)\n","        output_sentence = ' '.join(output_words)\n","        print('predicted {}'.format(output_sentence))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wd1JctGVFuDA"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xky23N_RFuDA"},"source":["# train GRU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNrsWxs_FuDA","outputId":"83ae6a07-0003-4602-a6fb-63e66e71b09e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Read 49609 sentence pairs\n","Maximum lenght of input is 11\n","random sentence ['Ú†Ùˆ Ø¨Ø®Ø´Ù†Ø¯Ù‡ Ø§Ù… Ø¨ÛŒØ´ Ø¨Ø³Ù¾Ø§Ø±Ù…Ø´', 'Ú©Ù„Ø§Ù‡ Ø§Ø² Ø¨Ø± Ú†Ø±Ø® Ø¨Ú¯Ø°Ø§Ø±Ù…Ø´']\n","Input : 12687 Output : 13323\n","Encoder(\n","  (embedding): Embedding(12687, 256, padding_idx=2)\n","  (recurrent): GRU(256, 512)\n",")\n","Decoder(\n","  (embedding): Embedding(13323, 256, padding_idx=2)\n","  (recurrent): GRU(256, 512)\n","  (out): Linear(in_features=512, out_features=13323, bias=True)\n","  (softmax): LogSoftmax(dim=1)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 4999/100000 [02:54<54:59, 28.79it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :5000 , Loss : 3.6835600317001482 , score :0.30085014668087895\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|â–ˆ         | 10000/100000 [05:48<1:20:48, 18.56it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :10000 , Loss : 3.498808099969217 , score :0.5929966326562244\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 15000/100000 [08:50<1:15:49, 18.68it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :15000 , Loss : 3.456614892419176 , score :0.8847852617226406\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|â–ˆâ–‰        | 19998/100000 [11:52<47:10, 28.27it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :20000 , Loss : 3.4310910407384325 , score :1.1698831124777924\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–       | 24999/100000 [14:49<43:55, 28.46it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :25000 , Loss : 3.4265187446912235 , score :1.4549786330733296\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–‰       | 29999/100000 [17:46<40:16, 28.97it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :30000 , Loss : 3.4146651433944624 , score :1.7400763999463467\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–      | 34998/100000 [20:52<40:09, 26.98it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :35000 , Loss : 3.396766833464302 , score :2.025135047119711\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–‰      | 39999/100000 [23:57<37:29, 26.67it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :40000 , Loss : 3.4081081892967244 , score :2.3101928686417703\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45000/100000 [27:02<49:27, 18.54it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :45000 , Loss : 3.4064408769925425 , score :2.595247639205983\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49998/100000 [30:05<30:48, 27.05it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :50000 , Loss : 3.3961033751487855 , score :2.8803054816986564\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54999/100000 [33:10<27:29, 27.29it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :55000 , Loss : 3.404873932902023 , score :3.1645525111728348\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60000/100000 [36:15<35:56, 18.55it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :60000 , Loss : 3.400897659842174 , score :3.4489375964895967\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64998/100000 [39:18<21:49, 26.72it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :65000 , Loss : 3.3876089165051746 , score :3.733239543205024\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69999/100000 [42:23<18:30, 27.01it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :70000 , Loss : 3.403670941670735 , score :4.0164240766089305\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75000/100000 [45:27<22:41, 18.36it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :75000 , Loss : 3.3896361064275085 , score :4.300357620164314\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79998/100000 [48:32<12:09, 27.43it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :80000 , Loss : 3.4077032384872408 , score :4.58256508431767\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84999/100000 [51:37<09:20, 26.77it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :85000 , Loss : 3.3993611530303918 , score :4.866305654789221\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90000/100000 [54:42<08:57, 18.60it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :90000 , Loss : 3.3982938988049916 , score :5.151107958591581\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94998/100000 [57:47<03:01, 27.49it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :95000 , Loss : 3.3996316342989608 , score :5.435722628486341\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [1:00:52<00:00, 27.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["iter :100000 , Loss : 3.3889591455459644 , score :5.720267126350617\n","source Ø¨Ø²Ø¯ ÛŒÚ© Ø¯Ù… Ø¢Ù† Ø§Ú˜Ø¯Ù‡Ø§ÛŒ Ù¾Ù„ÛŒØ¯\n","target ØªÙ†ÛŒ Ú†Ù†Ø¯ Ø§Ø²ÛŒØ´Ø§Ù† Ø¨Ù‡ Ø¯Ù… Ø¯Ø±Ú©Ø´ÛŒØ¯\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø§Ø²Ø§Ù† Ù¾Ø³ Ú†Ùˆ ÙØ±Ù…Ø§ÛŒØ¯Ù… Ø´Ù‡Ø±ÛŒØ§Ø±\n","target Ø¨ÛŒØ§ÛŒÙ… Ù¾Ø±Ø³ØªØ´ Ú©Ù†Ù… Ø¨Ù†Ø¯Ù‡ ÙˆØ§Ø±\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ù‡Ù…ÛŒ Ø¨ÙˆÛŒ Ù…Ù‡Ø± Ø¢Ù…Ø¯ Ø§Ø² Ø±ÙˆÛŒ Ø§Ùˆ\n","target Ù‡Ù…ÛŒ Ø²ÛŒØ¨ ØªØ§Ø¬ Ø¢Ù…Ø¯ Ø§Ø² Ù…ÙˆÛŒ Ø§Ùˆ\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ú†Ù†ÛŒÙ† Ú¯ÙØª Ú©Ø² Ø¨Ø§Ø±Ú¯Ø§Ù‡ Ø¨Ù„Ù†Ø¯\n","target Ø¨Ø±ÙØªÙ… Ø³ÙˆÛŒ Ø±Ø³ØªÙ… Ø¯ÛŒÙˆØ¨Ù†Ø¯\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø¨Ø®ÙˆØ±Ø¯Ù†Ø¯ Ø¨Ø§ Ø´ØªØ§Ø¨ Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø¨ÙˆØ¯\n","target Ù¾Ø³ Ø¢Ù†Ú¯Ù‡ Ø¨Ù‡ Ø²Ù…Ø²Ù… Ø¨Ú¯ÙØªÙ†Ø¯ Ø²ÙˆØ¯\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ú†Ùˆ Ø¨Ø´Ù†ÛŒØ¯ Ø§ÙØ±Ø§Ø³ÛŒØ§Ø¨ Ø§ÛŒÙ† Ø³Ø®Ù†\n","target Ù¾Ø´ÛŒÙ…Ø§Ù† Ø´Ø¯ Ø§Ø² Ú©Ø±Ø¯Ù‡ Ù‡Ø§ÛŒ Ú©Ù‡Ù†\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ú†Ù†ÛŒÙ† Ø¯Ø§Ø¯ Ù¾Ø§Ø³Ø® Ú©Ù‡ Ø¯Ø§Ù†Ø´ Ø¨Ù‡Ø³Øª\n","target Ú†Ùˆ Ø¯Ø§Ù†Ø§ Ø¨ÙˆØ¯ Ø¨Ø±Ù…Ù‡Ø§Ù† Ø¨Ø±Ù…Ù‡Ø³Øª\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ú¯Ø± Ø§ÛŒØ¯ÙˆÙ† Ú©Ù‡ Ø¨Ø± Ù…Ù† Ù†Ø³Ø§Ø²ÛŒØ¯ Ø¨Ø¯\n","target Ú©Ù†ÛŒØ¯ Ø¢Ù†Ú© Ø§Ø² Ø¯Ø§Ø¯ Ùˆ Ú¯Ø±Ø¯ÛŒ Ø³Ø²Ø¯\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø¨Ø¯Ùˆ Ú¯ÙØª Ø´Ø§Ù‡ Ø§ÛŒÙ† Ú©Ø¬Ø§ Ø¯Ø§Ø´ØªÛŒ\n","target Ù…Ø±Ø§ Ù…Ø³Øª Ú©Ø±Ø¯ÛŒ Ùˆ Ø¨Ú¯Ø°Ø§Ø´ØªÛŒ\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø§Ø² Ø§ÙØ±Ø§Ø² Ú†ÙˆÙ† Ú©Ú˜ Ú¯Ø±Ø¯Ø¯ Ø³Ù¾Ù‡Ø±\n","target Ù†Ù‡ ØªÙ†Ø¯ÛŒ Ø¨Ú©Ø§Ø± Ø¢ÛŒØ¯ Ø§Ø² Ø¨Ù† Ù†Ù‡ Ù…Ù‡Ø±\n","predicted Ú©Ù‡ Ø§Ø² Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n"]}],"source":["lang1 = 'M1'\n","lang2 = 'M2'\n","writer = SummaryWriter(log_dir=\"/content/drive/MyDrive/HW4_Q1/GRU_logs\")\n","source, target, pairs = process_data(lang1, lang2)\n","\n","randomize = random.choice(pairs)\n","print('random sentence {}'.format(randomize))\n","\n","#print number of words\n","input_size = source.n_words\n","output_size = target.n_words\n","print('Input : {} Output : {}'.format(input_size, output_size))\n","\n","embed_size = 256\n","hidden_size = 512\n","num_layers = 1\n","num_iteration = 100000\n","\n","#create encoder-decoder model\n","encoder = Encoder(input_size, hidden_size, embed_size, num_layers,GRU=True)\n","decoder = Decoder(output_size, hidden_size, embed_size, num_layers,GRU=True)\n","\n","model = Seq2Seq(encoder, decoder, device,mode='GRU').to(device)\n","\n","#print model \n","print(encoder)\n","print(decoder)\n","\n","model = trainModel(model, source, target, pairs, num_iteration,type='GRU')\n","evaluateRandomly(model, source, target, pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pm2VIpKGyxTR"},"outputs":[],"source":["%reload_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHk1Gw7Qf7KM"},"outputs":[],"source":["# set correct path of GRU_logs in your system\n","%tensorboard --logdir \"/content/drive/MyDrive/HW4_Q1/GRU_logs\""]},{"cell_type":"markdown","metadata":{"id":"fRwRoy7Cf7eT"},"source":["# train LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2w9YXZsaZ_j","outputId":"80de3db0-beec-4c75-ce18-3030e2dca3f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Read 49609 sentence pairs\n","Maximum lenght of input is 11\n","random sentence ['Ø¨Ø¯ÛŒÙ† Ú©Ø§Ø± Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú¯Ø±Ø¯ Ø¢Ù…Ø¯Ù†Ø¯', 'Ø¨Ø³ÛŒ Ø²ÛŒÙ† Ù†Ø´Ø§Ù† Ø¯Ø§Ø³ØªØ§Ù†Ù‡Ø§ Ø²Ø¯Ù†Ø¯']\n","Input : 12687 Output : 13323\n","Encoder(\n","  (embedding): Embedding(12687, 256, padding_idx=2)\n","  (recurrent): LSTM(256, 512)\n",")\n","Decoder(\n","  (embedding): Embedding(13323, 256, padding_idx=2)\n","  (recurrent): LSTM(256, 512)\n","  (out): Linear(in_features=512, out_features=13323, bias=True)\n","  (softmax): LogSoftmax(dim=1)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  5%|â–         | 4998/100000 [03:11<1:00:26, 26.19it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :5000 , Loss : 3.5659987035433542 , score :0.2978983691102564\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|â–‰         | 9999/100000 [06:26<58:31, 25.63it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :10000 , Loss : 3.4073303403854442 , score :0.5829569743414826\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 15000/100000 [09:41<1:22:35, 17.15it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :15000 , Loss : 3.4057777534167095 , score :0.8680148168332474\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|â–ˆâ–‰        | 19998/100000 [12:55<52:19, 25.48it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :20000 , Loss : 3.399622452259068 , score :1.1530734430350886\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–       | 24999/100000 [16:09<47:27, 26.34it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :25000 , Loss : 3.398562683931982 , score :1.4381190607248526\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 30000/100000 [19:22<1:07:14, 17.35it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :30000 , Loss : 3.377958038584395 , score :1.7229839091624468\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–      | 34998/100000 [22:35<41:31, 26.09it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :35000 , Loss : 3.383033891232812 , score :2.007980711527563\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–‰      | 39999/100000 [25:48<38:08, 26.22it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :40000 , Loss : 3.387989025402062 , score :2.2928005583375444\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45000/100000 [29:01<53:44, 17.06it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :45000 , Loss : 3.3956036910692906 , score :2.5776654067757714\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49998/100000 [32:14<32:17, 25.81it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :50000 , Loss : 3.3885641391754167 , score :2.862634750520263\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54999/100000 [35:27<28:31, 26.29it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :55000 , Loss : 3.3790883762995385 , score :3.1473180669665846\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60000/100000 [38:40<38:25, 17.35it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :60000 , Loss : 3.377978123188024 , score :3.432171474312885\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64998/100000 [41:53<22:02, 26.46it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :65000 , Loss : 3.3819395123481817 , score :3.717229295834944\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69999/100000 [45:06<19:05, 26.19it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :70000 , Loss : 3.3859584886232974 , score :4.002287117357003\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75000/100000 [48:19<23:35, 17.66it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :75000 , Loss : 3.3835992897033806 , score :4.287339599702831\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79998/100000 [51:32<12:49, 25.99it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :80000 , Loss : 3.382188943926482 , score :4.572398204934966\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84999/100000 [54:40<10:14, 24.41it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :85000 , Loss : 3.38394076156616 , score :4.857456026457025\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90000/100000 [57:43<09:22, 17.77it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :90000 , Loss : 3.3865597101847356 , score :5.142513847979084\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94998/100000 [1:00:45<03:03, 27.29it/s]"]},{"name":"stdout","output_type":"stream","text":["iter :95000 , Loss : 3.387362746270491 , score :5.427571669501144\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [1:03:48<00:00, 26.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["iter :100000 , Loss : 3.373803162066143 , score :5.712629491023203\n","source Ú¯Ø± Ø¢Ø²Ø§Ø± Ø¨ÙˆØ¯ÛŒØ´ Ø¯Ø± Ø¯Ù„ Ø² Ù…Ù†\n","target Ø³Ø±Ù… Ø¨Ø±Ù†ÛŒÙØ±Ø§Ø®ØªÛŒ Ø² Ø§Ù†Ø¬Ù…Ù†\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø² Ø®ÙˆÛŒØ´Ø§Ù† Ú¯Ø²ÛŒÙ† Ú©Ø±Ø¯ Ù¾ÛŒØ±Ø§Ù† Ù‡Ø²Ø§Ø±\n","target Ù¾Ø°ÛŒØ±Ù‡ Ø´Ø¯Ù† Ø±Ø§ Ø¨Ø±Ø¢Ø±Ø§Ø³Øª Ú©Ø§Ø±\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø¨ÛŒØ§ÛŒÛŒØ¯ ÛŒÚ©Ø³Ø± Ø¨Ù‡ Ø¯Ø±Ú¯Ø§Ù‡ Ù…Ù†\n","target Ú©Ù‡ Ø¨Ø± Ù…Ø±Ø² Ø¨Ú¯Ø°Ø´Øª Ø¨Ø¯ Ø®ÙˆØ§Ù‡ Ù…Ù†\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source ØªÙˆ Ø¨Ù†Ø¯ÛŒØ´ Ù‡Ø´ÛŒØ§Ø± Ùˆ Ø¨Ú¯Ø´Ø§ÛŒ Ú¯ÙˆØ´\n","target Ø³Ø®Ù† Ø§Ø² Ø®Ø±Ø¯Ù…Ù†Ø¯ Ù…Ø±Ø¯Ù… Ù†ÛŒÙˆØ´\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø¨Ù‡ ØªÙ†Ù‡Ø§ ØªÙ† Ø®ÙˆÛŒØ´ Ø¬ÙˆÛŒÙ… Ù†Ø¨Ø±Ø¯\n","target Ø² Ù„Ø´Ú©Ø± Ù†Ø®ÙˆØ§Ù‡Ù… Ú©Ø³ÛŒ Ø±Ù†Ø¬Ù‡ Ú©Ø±Ø¯\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ù†Ø®Ø³Øª Ø¢ÙØ±ÛŒÙ† Ú©Ø±Ø¯ Ø¨Ø± Ú©Ø±Ø¯Ú¯Ø§Ø±\n","target Ø¬Ù‡Ø§Ù†Ø¯Ø§Ø± Ù¾ÛŒØ±ÙˆØ² Ùˆ Ù¾Ø±ÙˆØ±Ø¯Ú¯Ø§Ø±\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ú†Ù†ÛŒÙ† Ø¯Ø§Ø¯ Ù¾Ø§Ø³Ø® Ú©Ù‡ Ø§Ø² Ø¨ÛŒØ´ Ø®ÙˆØ±Ø¯\n","target Ù…Ú¯Ø± Ø¢Ø±Ø²Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø¯ Ø¨Ø¯Ø±Ø¯\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ø¨Ø¯Ùˆ Ú¯ÙØª Ø²Ø§Ù„ Ø§ÛŒ Ù¾Ø³Ø± Ø§ÛŒÙ† Ø³Ø®Ù†\n","target Ù…Ú¯ÙˆÛŒ Ùˆ Ø¬Ø¯Ø§ Ú©Ù† Ø³Ø±Ø´ Ø±Ø§ Ø² Ø¨Ù†\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source Ú†Ùˆ Ù‡Ù†Ú¯Ø§Ù… Ø±ÙØªÙ† ÙØ±Ø§Ø² Ø¢ÛŒØ¯Øª\n","target Ø¨Ù‡ Ø¯ÛŒØ¯Ø§Ø± Ø®Ø³Ø±Ùˆ Ù†ÛŒØ§Ø² Ø¢ÛŒØ¯Øª\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n","source ÛŒÚ©ÛŒ Ø¨Ø±Ú¯Ø²ÛŒÙ†Ø¯ Ú©Ù‡ Ù†Ø§Ù…ÛŒ ØªØ±Ø³Øª\n","target Ø¨Ù‡ Ø®Ø§Ù‚Ø§Ù† Ú†ÛŒÙ† Ø¨Ø±Ú¯Ø±Ø§Ù…ÛŒ ØªØ±Ø³Øª\n","predicted Ú©Ù‡ Ùˆ Ùˆ Ùˆ PAD PAD PAD PAD PAD PAD PAD <EOS>\n"]}],"source":["lang1 = 'M1'\n","lang2 = 'M2'\n","writer = SummaryWriter(log_dir=\"/content/drive/MyDrive/HW4_Q1/LSTM_logs\")\n","source, target, pairs = process_data(lang1, lang2)\n","\n","randomize = random.choice(pairs)\n","print('random sentence {}'.format(randomize))\n","\n","#print number of words\n","input_size = source.n_words\n","output_size = target.n_words\n","print('Input : {} Output : {}'.format(input_size, output_size))\n","\n","embed_size = 256\n","hidden_size = 512\n","num_layers = 1\n","num_iteration = 100000\n","\n","#create encoder-decoder model\n","encoder = Encoder(input_size, hidden_size, embed_size, num_layers,GRU=False)\n","decoder = Decoder(output_size, hidden_size, embed_size, num_layers,GRU=False)\n","\n","model = Seq2Seq(encoder, decoder, device,mode='LSTM').to(device)\n","\n","#print model \n","print(encoder)\n","print(decoder)\n","\n","model = trainModel(model, source, target, pairs, num_iteration,type='LSTM')\n","evaluateRandomly(model, source, target, pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiVI5TdorzSQ"},"outputs":[],"source":["# set correct path of GRU_logs in your system\n","%tensorboard --logdir \"/content/drive/MyDrive/HW4_Q1/LSTM_logs\""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["xegIjXECqwlF","EuGeZ-Jmq7iu","sHAUAgOSsATM","BmnrWQT9FuCy","3Oj4Yc1UFuC-","zm6otv8sFuC_","xky23N_RFuDA","fRwRoy7Cf7eT"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"06471efb792b4cf0b4605edc272142b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c55ffad6a8246aa97c10d4a4e9f0c9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c64a6a50d9e4c41a5f1d7591700c859":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1916a5d353a94dea80b79af06f33ce68","IPY_MODEL_df3788559ea5425396b38dfa6e55c1e5","IPY_MODEL_2390946e0905462894fb8c1959e42fe8"],"layout":"IPY_MODEL_672277e98bee42e6b9c521307bb0060e"}},"1916a5d353a94dea80b79af06f33ce68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30ebee065ee64ce68dfacd1eb122f997","placeholder":"â€‹","style":"IPY_MODEL_314094a449444440bd65e2472b7425b3","value":"Downloading builder script: "}},"2390946e0905462894fb8c1959e42fe8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8472e955bf74dc1a43e16ec64d006f3","placeholder":"â€‹","style":"IPY_MODEL_bad9a9f9fc6f466b97c0bca94343ae77","value":" 7.65k/? [00:00&lt;00:00, 392kB/s]"}},"30ebee065ee64ce68dfacd1eb122f997":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"314094a449444440bd65e2472b7425b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"672277e98bee42e6b9c521307bb0060e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad9a9f9fc6f466b97c0bca94343ae77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8472e955bf74dc1a43e16ec64d006f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df3788559ea5425396b38dfa6e55c1e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06471efb792b4cf0b4605edc272142b4","max":2848,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c55ffad6a8246aa97c10d4a4e9f0c9d","value":2848}}}}},"nbformat":4,"nbformat_minor":0}
