{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDahmgQGem9p"
      },
      "source": [
        "# Prepair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbIUd6pCFuCk",
        "outputId": "e67151ee-1471-46e7-b99f-bd5f8f30fe50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warning copy ferdousi.txt in this directory or copy form google drive form correct path!\n"
      ],
      "metadata": {
        "id": "pdWYuIDzz2TS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SjIOMrT9FuCn"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/HW4_Q1/ferdousi.txt .\n",
        "!cp /content/drive/MyDrive/HW4_Q1_notebook/ferdousi.txt ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BP-5Jrudn73Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "361b48e4-b473-4174-9e0d-6c11cadedb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install sacrebleu\n",
        "!pip install tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "0R-_9DG8tBBw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xAAMKtbEFuCo"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ObbPHJJvd57y"
      },
      "outputs": [],
      "source": [
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqCLrrSHmaTj",
        "outputId": "1368382c-8bed-44b1-e182-ceac459ced55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/glove/vectors.zip\n",
            "To: /content/vectors.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.2M/48.2M [00:00<00:00, 203MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  vectors.zip\n",
            "  inflating: vectors.txt             \n"
          ]
        }
      ],
      "source": [
        "gdown.download(url=\"https://github.com/Text-Mining/Persian-Wikipedia-Corpus/raw/master/models/glove/vectors.zip\",output=\"vectors.zip\")\n",
        "!unzip \"vectors.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXUYdGpMFuCq"
      },
      "source": [
        "# Data PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R9CGMKbXFuCs"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "MAX_LENGTH = 0\n",
        "\n",
        "#initialize Lang Class\n",
        "class Lang:\n",
        "   def __init__(self):\n",
        "       #initialize containers to hold the words and corresponding index\n",
        "       self.word2index = {}\n",
        "       self.word2count = {}\n",
        "       self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\"} #\n",
        "       self.n_words = 3  # Count SOS and EOS and PAD\n",
        "\n",
        "#split a sentence into words and add it to the container\n",
        "   def addSentence(self, sentence):\n",
        "       for word in sentence.split(' '):\n",
        "           self.addWord(word)\n",
        "\n",
        "#If the word is not in the container, the word will be added to it, \n",
        "#else, update the word counter\n",
        "   def addWord(self, word):\n",
        "       if word not in self.word2index:\n",
        "           self.word2index[word] = self.n_words\n",
        "           self.word2count[word] = 1\n",
        "           self.index2word[self.n_words] = word\n",
        "           self.n_words += 1\n",
        "       else:\n",
        "           self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "S6F9ZwDiFuCt"
      },
      "outputs": [],
      "source": [
        "def read_sentence(df, lang1, lang2):\n",
        "   sentence1 = df[lang1]\n",
        "   sentence2 = df[lang2]\n",
        "   return sentence1, sentence2\n",
        "   \n",
        "def Word2vec(path=\"/content/vectors.txt\"):\n",
        "  file=open(path, mode=\"r\")\n",
        "  L=file.readlines(-1)\n",
        "  Word_feature={}\n",
        "  for i in L:\n",
        "    vect=i.split()\n",
        "    Word_feature[vect[0]]=np.array(vect[1:],dtype=float)\n",
        "  return Word_feature\n",
        "\n",
        "def read_file(loc, lang1, lang2):\n",
        "   df = pd.read_csv(loc, delimiter='\\n', header=None, names=['Beyt'])[2::]\n",
        "   d = {lang1:df[0::2].values[:,0].tolist() , lang2: df[1::2].values[:,0].tolist()}\n",
        "   df=pd.DataFrame(d)\n",
        "   return df\n",
        "\n",
        "def process_data(lang1,lang2):\n",
        "   global MAX_LENGTH\n",
        "   df = read_file('ferdousi.txt', lang1, lang2)\n",
        "   print(\"Read %s sentence pairs\" % len(df))\n",
        "   sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
        "  #  print(sentence1[0])\n",
        "   source = Lang()\n",
        "   target = Lang()\n",
        "   pairs = []\n",
        "\n",
        "   for i in range(len(df)):\n",
        "      if len(sentence1[i].split(' '))>MAX_LENGTH:\n",
        "         MAX_LENGTH = len(sentence1[i].split(' '))\n",
        "     \n",
        "      full = [sentence1[i], sentence2[i]]\n",
        "      source.addSentence(sentence1[i])\n",
        "      target.addSentence(sentence2[i])\n",
        "      pairs.append(full)\n",
        "\n",
        "   print(f\"Maximum lenght of input is {MAX_LENGTH}\")\n",
        "\n",
        "   return source, target, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_mlMEoMFuCu",
        "outputId": "cf841d20-26e6-4b56-946e-ab29625b92d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 49609 sentence pairs\n",
            "Maximum lenght of input is 11\n"
          ]
        }
      ],
      "source": [
        "lang1 = 'M1'\n",
        "lang2 = 'M2'\n",
        "# a=read_file('ferdousi.txt', lang1, lang2)\n",
        "source, target, pairs = process_data(lang1, lang2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "I6XufbzrFuCw"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "   return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "   global PAD_token\n",
        "   global MAX_LENGTH\n",
        "   indexes = indexesFromSentence(lang, sentence)\n",
        "   pad_list=[PAD_token for i in range(MAX_LENGTH-len(indexes))]\n",
        "   indexes =  indexes  + pad_list\n",
        "   indexes.append(EOS_token)\n",
        "   return torch.tensor(indexes, dtype=torch.long,device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "   input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "   target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "   return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Yw3WLD_FuCx"
      },
      "outputs": [],
      "source": [
        "training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n",
        "                     for i in range(10)]\n",
        "                     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rk7L_RqRJJ8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44109603-0667-43e8-fc44-c486062de82d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([[ 106],\n",
              "          [1269],\n",
              "          [  48],\n",
              "          [ 176],\n",
              "          [ 705],\n",
              "          [  37],\n",
              "          [1161],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[ 110],\n",
              "          [  83],\n",
              "          [1429],\n",
              "          [  13],\n",
              "          [  83],\n",
              "          [4805],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[1420],\n",
              "          [   7],\n",
              "          [3896],\n",
              "          [   7],\n",
              "          [2071],\n",
              "          [ 490],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[  52],\n",
              "          [4177],\n",
              "          [ 184],\n",
              "          [ 183],\n",
              "          [ 208],\n",
              "          [ 705],\n",
              "          [ 705],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[ 328],\n",
              "          [  83],\n",
              "          [5853],\n",
              "          [ 842],\n",
              "          [ 464],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[ 178],\n",
              "          [ 117],\n",
              "          [  25],\n",
              "          [  28],\n",
              "          [ 201],\n",
              "          [ 159],\n",
              "          [6596],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[ 135],\n",
              "          [  19],\n",
              "          [  38],\n",
              "          [ 352],\n",
              "          [2773],\n",
              "          [ 213],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[ 296],\n",
              "          [3176],\n",
              "          [2465],\n",
              "          [  58],\n",
              "          [ 156],\n",
              "          [3366],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[3238],\n",
              "          [ 371],\n",
              "          [ 235],\n",
              "          [ 473],\n",
              "          [ 334],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[1383],\n",
              "          [  69],\n",
              "          [2605],\n",
              "          [  24],\n",
              "          [ 141],\n",
              "          [  52],\n",
              "          [  32],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[117],\n",
              "          [ 19],\n",
              "          [ 38],\n",
              "          [620],\n",
              "          [ 68],\n",
              "          [ 72],\n",
              "          [  2],\n",
              "          [  2],\n",
              "          [  2],\n",
              "          [  2],\n",
              "          [  2],\n",
              "          [  1]], device='cuda:0'), tensor([[  67],\n",
              "          [ 465],\n",
              "          [1290],\n",
              "          [  13],\n",
              "          [ 630],\n",
              "          [  27],\n",
              "          [ 105],\n",
              "          [ 456],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[1155],\n",
              "          [ 157],\n",
              "          [   7],\n",
              "          [2046],\n",
              "          [2504],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[  296],\n",
              "          [   27],\n",
              "          [  291],\n",
              "          [  567],\n",
              "          [11170],\n",
              "          [ 1541],\n",
              "          [    2],\n",
              "          [    2],\n",
              "          [    2],\n",
              "          [    2],\n",
              "          [    2],\n",
              "          [    1]], device='cuda:0')), (tensor([[  21],\n",
              "          [  83],\n",
              "          [3410],\n",
              "          [1130],\n",
              "          [ 397],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[1237],\n",
              "          [  24],\n",
              "          [  71],\n",
              "          [ 783],\n",
              "          [2034],\n",
              "          [ 250],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[  21],\n",
              "          [  83],\n",
              "          [1130],\n",
              "          [  80],\n",
              "          [ 129],\n",
              "          [1473],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[  25],\n",
              "          [  43],\n",
              "          [ 653],\n",
              "          [ 385],\n",
              "          [4156],\n",
              "          [1886],\n",
              "          [1609],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0')), (tensor([[  33],\n",
              "          [1008],\n",
              "          [ 188],\n",
              "          [  37],\n",
              "          [2605],\n",
              "          [2226],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'), tensor([[2936],\n",
              "          [  13],\n",
              "          [ 959],\n",
              "          [ 112],\n",
              "          [ 448],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   2],\n",
              "          [   1]], device='cuda:0'))]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "training_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmnrWQT9FuCy"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bCQ5JSxqFuCy"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "   def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers,GRU=False):\n",
        "       super(Encoder, self).__init__()\n",
        "      \n",
        "       #set the encoder input dimesion , embbed dimesion, hidden dimesion, and number of layers \n",
        "       self.input_dim = input_dim\n",
        "       self.embbed_dim = embbed_dim\n",
        "       self.hidden_dim = hidden_dim\n",
        "       self.num_layers = num_layers\n",
        "\n",
        "       #initialize the embedding layer with input and embbed dimention\n",
        "       self.embedding = nn.Embedding(input_dim, self.embbed_dim,padding_idx=2) #\n",
        "       #intialize the GRU to take the input dimetion of embbed, and output dimention of hidden and\n",
        "       #set the number of gru layers\n",
        "       if GRU:\n",
        "        self.recurrent = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "       else:\n",
        "        self.recurrent = nn.LSTM(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "              \n",
        "   def forward(self, src):\n",
        "       \n",
        "       embedded = self.embedding(src).view(1,1,-1)\n",
        "       outputs, hidden = self.recurrent(embedded)\n",
        "       return outputs, hidden\n",
        "   def initHidden(self):\n",
        "     return torch.zeros(1, 1, self.hidden_dim, device=device)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "   def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers,GRU=False):\n",
        "       super(Decoder, self).__init__()\n",
        "\n",
        "#set the encoder output dimension, embed dimension, hidden dimension, and number of layers \n",
        "       self.embbed_dim = embbed_dim\n",
        "       self.hidden_dim = hidden_dim\n",
        "       self.output_dim = output_dim\n",
        "       self.num_layers = num_layers\n",
        "\n",
        "# initialize every layer with the appropriate dimension. For the decoder layer, it will consist of an embedding, GRU, a Linear layer and a Log softmax activation function.\n",
        "       self.embedding = nn.Embedding(output_dim, self.embbed_dim ,padding_idx=2) # \n",
        "       \n",
        "       if GRU:\n",
        "        self.recurrent = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "       else :\n",
        "        self.recurrent=nn.LSTM(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "\n",
        "       self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "       self.softmax = nn.LogSoftmax(dim=1)\n",
        "      \n",
        "   def forward(self, input, hidden):\n",
        "\n",
        "# reshape the input to (1, batch_size)\n",
        "       input = input.view(1, -1)\n",
        "       embedded = F.relu(self.embedding(input))\n",
        "       output, hidden = self.recurrent(embedded, hidden)       \n",
        "       prediction = self.softmax(self.out(output[0]))\n",
        "      \n",
        "       return prediction, hidden\n",
        "   def initHidden(self):\n",
        "      return torch.zeros(1, 1, self.hidden_dim, device=device)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "   def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH,mode='GRU'):\n",
        "       super().__init__()\n",
        "      \n",
        "#initialize the encoder and decoder\n",
        "       self.encoder = encoder\n",
        "       self.decoder = decoder\n",
        "       self.device = device\n",
        "       self.mode = mode\n",
        "   def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "\n",
        "       input_length = source.size(0) #get the input length (number of words in sentence)\n",
        "       batch_size = target.shape[1] \n",
        "       target_length = target.shape[0]\n",
        "       vocab_size = self.decoder.output_dim\n",
        "      \n",
        "#initialize a variable to hold the predicted outputs\n",
        "       outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "#encode every word in a sentence\n",
        "       for i in range(input_length):\n",
        "           encoder_output, encoder_hidden = self.encoder(source[i])\n",
        "\n",
        "#use the encoder‚Äôs hidden layer as the decoder hidden\n",
        "       \n",
        "       if self.mode == \"GRU\":\n",
        "         decoder_hidden = encoder_hidden.to(device)\n",
        "       elif self.mode == \"LSTM\":\n",
        "         decoder_hidden = (encoder_hidden[0].to(device),encoder_hidden[1].to(device))\n",
        "       \n",
        "#add a token before the first predicted word\n",
        "       decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
        "\n",
        "#topk is used to get the top K value over a list\n",
        "#predict the output word from the current target word. If we enable the teaching force,  then the #next decoder input is the next word, else, use the decoder output highest value. \n",
        "\n",
        "       for t in range(target_length):   \n",
        "           decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "           outputs[t] = decoder_output\n",
        "           teacher_force = random.random() < teacher_forcing_ratio\n",
        "           topv, topi = decoder_output.topk(1)\n",
        "           input = (target[t] if teacher_force else topi)\n",
        "           if(teacher_force == False and input.item() == EOS_token):\n",
        "               break\n",
        "\n",
        "       return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Oj4Yc1UFuC-"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OJWRGTEDFuC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0c64a6a50d9e4c41a5f1d7591700c859",
            "1916a5d353a94dea80b79af06f33ce68",
            "df3788559ea5425396b38dfa6e55c1e5",
            "2390946e0905462894fb8c1959e42fe8",
            "672277e98bee42e6b9c521307bb0060e",
            "30ebee065ee64ce68dfacd1eb122f997",
            "314094a449444440bd65e2472b7425b3",
            "06471efb792b4cf0b4605edc272142b4",
            "0c55ffad6a8246aa97c10d4a4e9f0c9d",
            "d8472e955bf74dc1a43e16ec64d006f3",
            "bad9a9f9fc6f466b97c0bca94343ae77"
          ]
        },
        "outputId": "2b661dfc-2e48-42f3-e9b1-a6ca8f41de2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-4d2c4558e126>:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric('sacrebleu')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c64a6a50d9e4c41a5f1d7591700c859"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "import datasets\n",
        "\n",
        "metric = datasets.load_metric('sacrebleu')\n",
        "\n",
        "def clacModel(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "\n",
        "   model_optimizer.zero_grad()\n",
        "\n",
        "   input_length = input_tensor.size(0)\n",
        "   loss = 0\n",
        "   epoch_loss = 0\n",
        "   # print(input_tensor.shape)\n",
        "\n",
        "   output = model(input_tensor, target_tensor,teacher_forcing_ratio)\n",
        "\n",
        "   num_iter = output.size(0)\n",
        "  #  print(num_iter)\n",
        "\n",
        "#calculate the loss from a predicted sentence with the expected result\n",
        "   for ot in range(num_iter):\n",
        "       loss += criterion(output[ot], target_tensor[ot])\n",
        "       \n",
        "   metric.add(predictions=output, references=target_tensor)\n",
        "   \n",
        "   loss.backward()\n",
        "   model_optimizer.step()\n",
        "   epoch_loss = loss.item() / num_iter\n",
        "\n",
        "   return epoch_loss,metric\n",
        "\n",
        "def trainModel(model, source, target, pairs, num_iteration=20000,type='GRU'):\n",
        "   \n",
        "   model.train()\n",
        "\n",
        "  #  optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "   optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\n",
        "  #  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=num_iteration//5000,eta_min=1e-4,last_epoch=-1)\n",
        "  #  criterion = nn.NLLLoss()\n",
        "   criterion = nn.CrossEntropyLoss()\n",
        "   total_loss_iterations = 0\n",
        "   final_score = 0\n",
        "   training_pairs = [tensorsFromPair(source, target, random.choice(pairs))\n",
        "                     for i in range(num_iteration)]\n",
        "  \n",
        "   for iter in tqdm(range(1, num_iteration+1)):\n",
        "       training_pair = training_pairs[iter - 1]\n",
        "       input_tensor = training_pair[0]\n",
        "       target_tensor = training_pair[1]\n",
        "\n",
        "       loss,metric = clacModel(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "       s  = metric.compute()\n",
        "\n",
        "       final_score += s['score']\n",
        "       \n",
        "       total_loss_iterations += loss\n",
        "       writer.add_scalar('Loss', loss,iter)\n",
        "       writer.add_scalar('score', s['score'],iter) \n",
        "\n",
        "       if iter % 5000 == 0:\n",
        "           avarage_loss= total_loss_iterations / 5000\n",
        "           avg_score = final_score /5000\n",
        "           total_loss_iterations = 0\n",
        "           tqdm.write(f'iter :{iter} , Loss : {avarage_loss} , score :{avg_score}')\n",
        "          #  scheduler.step()\n",
        "           torch.save(model.state_dict(), f'/content/drive/MyDrive/HW4_Q1/{type}_Model.pt')\n",
        "          \n",
        "   return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm6otv8sFuC_"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Gabw_5sDFuC_"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        output = model(input_tensor, output_tensor)\n",
        "        # print(output_tensor)\n",
        "\n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "            # print(topi)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateRandomly(model, source, target, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('source {}'.format(pair[0]))\n",
        "        print('target {}'.format(pair[1]))\n",
        "        output_words = evaluate(model, source, target, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted {}'.format(output_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wd1JctGVFuDA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xky23N_RFuDA"
      },
      "source": [
        "# train GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNrsWxs_FuDA",
        "outputId": "83ae6a07-0003-4602-a6fb-63e66e71b09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 49609 sentence pairs\n",
            "Maximum lenght of input is 11\n",
            "random sentence ['⁄ÜŸà ÿ®ÿÆÿ¥ŸÜÿØŸá ÿßŸÖ ÿ®€åÿ¥ ÿ®ÿ≥Ÿæÿßÿ±ŸÖÿ¥', '⁄©ŸÑÿßŸá ÿßÿ≤ ÿ®ÿ± ⁄Üÿ±ÿÆ ÿ®⁄Øÿ∞ÿßÿ±ŸÖÿ¥']\n",
            "Input : 12687 Output : 13323\n",
            "Encoder(\n",
            "  (embedding): Embedding(12687, 256, padding_idx=2)\n",
            "  (recurrent): GRU(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(13323, 256, padding_idx=2)\n",
            "  (recurrent): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=13323, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|‚ñç         | 4999/100000 [02:54<54:59, 28.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :5000 , Loss : 3.6835600317001482 , score :0.30085014668087895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|‚ñà         | 10000/100000 [05:48<1:20:48, 18.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :10000 , Loss : 3.498808099969217 , score :0.5929966326562244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|‚ñà‚ñå        | 15000/100000 [08:50<1:15:49, 18.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :15000 , Loss : 3.456614892419176 , score :0.8847852617226406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|‚ñà‚ñâ        | 19998/100000 [11:52<47:10, 28.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :20000 , Loss : 3.4310910407384325 , score :1.1698831124777924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|‚ñà‚ñà‚ñç       | 24999/100000 [14:49<43:55, 28.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :25000 , Loss : 3.4265187446912235 , score :1.4549786330733296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|‚ñà‚ñà‚ñâ       | 29999/100000 [17:46<40:16, 28.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :30000 , Loss : 3.4146651433944624 , score :1.7400763999463467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|‚ñà‚ñà‚ñà‚ñç      | 34998/100000 [20:52<40:09, 26.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :35000 , Loss : 3.396766833464302 , score :2.025135047119711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|‚ñà‚ñà‚ñà‚ñâ      | 39999/100000 [23:57<37:29, 26.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :40000 , Loss : 3.4081081892967244 , score :2.3101928686417703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45000/100000 [27:02<49:27, 18.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :45000 , Loss : 3.4064408769925425 , score :2.595247639205983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49998/100000 [30:05<30:48, 27.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :50000 , Loss : 3.3961033751487855 , score :2.8803054816986564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54999/100000 [33:10<27:29, 27.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :55000 , Loss : 3.404873932902023 , score :3.1645525111728348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60000/100000 [36:15<35:56, 18.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :60000 , Loss : 3.400897659842174 , score :3.4489375964895967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64998/100000 [39:18<21:49, 26.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :65000 , Loss : 3.3876089165051746 , score :3.733239543205024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69999/100000 [42:23<18:30, 27.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :70000 , Loss : 3.403670941670735 , score :4.0164240766089305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75000/100000 [45:27<22:41, 18.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :75000 , Loss : 3.3896361064275085 , score :4.300357620164314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79998/100000 [48:32<12:09, 27.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :80000 , Loss : 3.4077032384872408 , score :4.58256508431767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84999/100000 [51:37<09:20, 26.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :85000 , Loss : 3.3993611530303918 , score :4.866305654789221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90000/100000 [54:42<08:57, 18.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :90000 , Loss : 3.3982938988049916 , score :5.151107958591581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94998/100000 [57:47<03:01, 27.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :95000 , Loss : 3.3996316342989608 , score :5.435722628486341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [1:00:52<00:00, 27.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :100000 , Loss : 3.3889591455459644 , score :5.720267126350617\n",
            "source ÿ®ÿ≤ÿØ €å⁄© ÿØŸÖ ÿ¢ŸÜ ÿß⁄òÿØŸáÿß€å ŸæŸÑ€åÿØ\n",
            "target ÿ™ŸÜ€å ⁄ÜŸÜÿØ ÿßÿ≤€åÿ¥ÿßŸÜ ÿ®Ÿá ÿØŸÖ ÿØÿ±⁄©ÿ¥€åÿØ\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿßÿ≤ÿßŸÜ Ÿæÿ≥ ⁄ÜŸà ŸÅÿ±ŸÖÿß€åÿØŸÖ ÿ¥Ÿáÿ±€åÿßÿ±\n",
            "target ÿ®€åÿß€åŸÖ Ÿæÿ±ÿ≥ÿ™ÿ¥ ⁄©ŸÜŸÖ ÿ®ŸÜÿØŸá Ÿàÿßÿ±\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ŸáŸÖ€å ÿ®Ÿà€å ŸÖŸáÿ± ÿ¢ŸÖÿØ ÿßÿ≤ ÿ±Ÿà€å ÿßŸà\n",
            "target ŸáŸÖ€å ÿ≤€åÿ® ÿ™ÿßÿ¨ ÿ¢ŸÖÿØ ÿßÿ≤ ŸÖŸà€å ÿßŸà\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ⁄ÜŸÜ€åŸÜ ⁄ØŸÅÿ™ ⁄©ÿ≤ ÿ®ÿßÿ±⁄ØÿßŸá ÿ®ŸÑŸÜÿØ\n",
            "target ÿ®ÿ±ŸÅÿ™ŸÖ ÿ≥Ÿà€å ÿ±ÿ≥ÿ™ŸÖ ÿØ€åŸàÿ®ŸÜÿØ\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ®ÿÆŸàÿ±ÿØŸÜÿØ ÿ®ÿß ÿ¥ÿ™ÿßÿ® ⁄Ü€åÿ≤€å ⁄©Ÿá ÿ®ŸàÿØ\n",
            "target Ÿæÿ≥ ÿ¢ŸÜ⁄ØŸá ÿ®Ÿá ÿ≤ŸÖÿ≤ŸÖ ÿ®⁄ØŸÅÿ™ŸÜÿØ ÿ≤ŸàÿØ\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ⁄ÜŸà ÿ®ÿ¥ŸÜ€åÿØ ÿßŸÅÿ±ÿßÿ≥€åÿßÿ® ÿß€åŸÜ ÿ≥ÿÆŸÜ\n",
            "target Ÿæÿ¥€åŸÖÿßŸÜ ÿ¥ÿØ ÿßÿ≤ ⁄©ÿ±ÿØŸá Ÿáÿß€å ⁄©ŸáŸÜ\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ⁄ÜŸÜ€åŸÜ ÿØÿßÿØ Ÿæÿßÿ≥ÿÆ ⁄©Ÿá ÿØÿßŸÜÿ¥ ÿ®Ÿáÿ≥ÿ™\n",
            "target ⁄ÜŸà ÿØÿßŸÜÿß ÿ®ŸàÿØ ÿ®ÿ±ŸÖŸáÿßŸÜ ÿ®ÿ±ŸÖŸáÿ≥ÿ™\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ⁄Øÿ± ÿß€åÿØŸàŸÜ ⁄©Ÿá ÿ®ÿ± ŸÖŸÜ ŸÜÿ≥ÿßÿ≤€åÿØ ÿ®ÿØ\n",
            "target ⁄©ŸÜ€åÿØ ÿ¢ŸÜ⁄© ÿßÿ≤ ÿØÿßÿØ Ÿà ⁄Øÿ±ÿØ€å ÿ≥ÿ≤ÿØ\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ®ÿØŸà ⁄ØŸÅÿ™ ÿ¥ÿßŸá ÿß€åŸÜ ⁄©ÿ¨ÿß ÿØÿßÿ¥ÿ™€å\n",
            "target ŸÖÿ±ÿß ŸÖÿ≥ÿ™ ⁄©ÿ±ÿØ€å Ÿà ÿ®⁄Øÿ∞ÿßÿ¥ÿ™€å\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿßÿ≤ ÿßŸÅÿ±ÿßÿ≤ ⁄ÜŸàŸÜ ⁄©⁄ò ⁄Øÿ±ÿØÿØ ÿ≥ŸæŸáÿ±\n",
            "target ŸÜŸá ÿ™ŸÜÿØ€å ÿ®⁄©ÿßÿ± ÿ¢€åÿØ ÿßÿ≤ ÿ®ŸÜ ŸÜŸá ŸÖŸáÿ±\n",
            "predicted ⁄©Ÿá ÿßÿ≤ Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n"
          ]
        }
      ],
      "source": [
        "lang1 = 'M1'\n",
        "lang2 = 'M2'\n",
        "writer = SummaryWriter(log_dir=\"/content/drive/MyDrive/HW4_Q1/GRU_logs\")\n",
        "source, target, pairs = process_data(lang1, lang2)\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "#print number of words\n",
        "input_size = source.n_words\n",
        "output_size = target.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 100000\n",
        "\n",
        "#create encoder-decoder model\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers,GRU=True)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers,GRU=True)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device,mode='GRU').to(device)\n",
        "\n",
        "#print model \n",
        "print(encoder)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, source, target, pairs, num_iteration,type='GRU')\n",
        "evaluateRandomly(model, source, target, pairs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "pm2VIpKGyxTR"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set correct path of GRU_logs in your system\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/HW4_Q1/GRU_logs\""
      ],
      "metadata": {
        "id": "AHk1Gw7Qf7KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 64860"
      ],
      "metadata": {
        "id": "h3Tcj3vKy3E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train LSTM"
      ],
      "metadata": {
        "id": "fRwRoy7Cf7eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang1 = 'M1'\n",
        "lang2 = 'M2'\n",
        "writer = SummaryWriter(log_dir=\"/content/drive/MyDrive/HW4_Q1/LSTM_logs\")\n",
        "source, target, pairs = process_data(lang1, lang2)\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "#print number of words\n",
        "input_size = source.n_words\n",
        "output_size = target.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 100000\n",
        "\n",
        "#create encoder-decoder model\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers,GRU=False)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers,GRU=False)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device,mode='LSTM').to(device)\n",
        "\n",
        "#print model \n",
        "print(encoder)\n",
        "print(decoder)\n",
        "\n",
        "model = trainModel(model, source, target, pairs, num_iteration,type='LSTM')\n",
        "evaluateRandomly(model, source, target, pairs)"
      ],
      "metadata": {
        "id": "j2w9YXZsaZ_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80de3db0-beec-4c75-ce18-3030e2dca3f9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 49609 sentence pairs\n",
            "Maximum lenght of input is 11\n",
            "random sentence ['ÿ®ÿØ€åŸÜ ⁄©ÿßÿ± ÿØÿ± Ÿæÿßÿ±ÿ≥ ⁄Øÿ±ÿØ ÿ¢ŸÖÿØŸÜÿØ', 'ÿ®ÿ≥€å ÿ≤€åŸÜ ŸÜÿ¥ÿßŸÜ ÿØÿßÿ≥ÿ™ÿßŸÜŸáÿß ÿ≤ÿØŸÜÿØ']\n",
            "Input : 12687 Output : 13323\n",
            "Encoder(\n",
            "  (embedding): Embedding(12687, 256, padding_idx=2)\n",
            "  (recurrent): LSTM(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (embedding): Embedding(13323, 256, padding_idx=2)\n",
            "  (recurrent): LSTM(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=13323, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|‚ñç         | 4998/100000 [03:11<1:00:26, 26.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :5000 , Loss : 3.5659987035433542 , score :0.2978983691102564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|‚ñâ         | 9999/100000 [06:26<58:31, 25.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :10000 , Loss : 3.4073303403854442 , score :0.5829569743414826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|‚ñà‚ñå        | 15000/100000 [09:41<1:22:35, 17.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :15000 , Loss : 3.4057777534167095 , score :0.8680148168332474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|‚ñà‚ñâ        | 19998/100000 [12:55<52:19, 25.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :20000 , Loss : 3.399622452259068 , score :1.1530734430350886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|‚ñà‚ñà‚ñç       | 24999/100000 [16:09<47:27, 26.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :25000 , Loss : 3.398562683931982 , score :1.4381190607248526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|‚ñà‚ñà‚ñà       | 30000/100000 [19:22<1:07:14, 17.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :30000 , Loss : 3.377958038584395 , score :1.7229839091624468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|‚ñà‚ñà‚ñà‚ñç      | 34998/100000 [22:35<41:31, 26.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :35000 , Loss : 3.383033891232812 , score :2.007980711527563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|‚ñà‚ñà‚ñà‚ñâ      | 39999/100000 [25:48<38:08, 26.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :40000 , Loss : 3.387989025402062 , score :2.2928005583375444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45000/100000 [29:01<53:44, 17.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :45000 , Loss : 3.3956036910692906 , score :2.5776654067757714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49998/100000 [32:14<32:17, 25.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :50000 , Loss : 3.3885641391754167 , score :2.862634750520263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54999/100000 [35:27<28:31, 26.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :55000 , Loss : 3.3790883762995385 , score :3.1473180669665846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60000/100000 [38:40<38:25, 17.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :60000 , Loss : 3.377978123188024 , score :3.432171474312885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64998/100000 [41:53<22:02, 26.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :65000 , Loss : 3.3819395123481817 , score :3.717229295834944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69999/100000 [45:06<19:05, 26.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :70000 , Loss : 3.3859584886232974 , score :4.002287117357003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75000/100000 [48:19<23:35, 17.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :75000 , Loss : 3.3835992897033806 , score :4.287339599702831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79998/100000 [51:32<12:49, 25.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :80000 , Loss : 3.382188943926482 , score :4.572398204934966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84999/100000 [54:40<10:14, 24.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :85000 , Loss : 3.38394076156616 , score :4.857456026457025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90000/100000 [57:43<09:22, 17.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :90000 , Loss : 3.3865597101847356 , score :5.142513847979084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94998/100000 [1:00:45<03:03, 27.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :95000 , Loss : 3.387362746270491 , score :5.427571669501144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [1:03:48<00:00, 26.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter :100000 , Loss : 3.373803162066143 , score :5.712629491023203\n",
            "source ⁄Øÿ± ÿ¢ÿ≤ÿßÿ± ÿ®ŸàÿØ€åÿ¥ ÿØÿ± ÿØŸÑ ÿ≤ ŸÖŸÜ\n",
            "target ÿ≥ÿ±ŸÖ ÿ®ÿ±ŸÜ€åŸÅÿ±ÿßÿÆÿ™€å ÿ≤ ÿßŸÜÿ¨ŸÖŸÜ\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ≤ ÿÆŸà€åÿ¥ÿßŸÜ ⁄Øÿ≤€åŸÜ ⁄©ÿ±ÿØ Ÿæ€åÿ±ÿßŸÜ Ÿáÿ≤ÿßÿ±\n",
            "target Ÿæÿ∞€åÿ±Ÿá ÿ¥ÿØŸÜ ÿ±ÿß ÿ®ÿ±ÿ¢ÿ±ÿßÿ≥ÿ™ ⁄©ÿßÿ±\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ®€åÿß€å€åÿØ €å⁄©ÿ≥ÿ± ÿ®Ÿá ÿØÿ±⁄ØÿßŸá ŸÖŸÜ\n",
            "target ⁄©Ÿá ÿ®ÿ± ŸÖÿ±ÿ≤ ÿ®⁄Øÿ∞ÿ¥ÿ™ ÿ®ÿØ ÿÆŸàÿßŸá ŸÖŸÜ\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ™Ÿà ÿ®ŸÜÿØ€åÿ¥ Ÿáÿ¥€åÿßÿ± Ÿà ÿ®⁄Øÿ¥ÿß€å ⁄ØŸàÿ¥\n",
            "target ÿ≥ÿÆŸÜ ÿßÿ≤ ÿÆÿ±ÿØŸÖŸÜÿØ ŸÖÿ±ÿØŸÖ ŸÜ€åŸàÿ¥\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ®Ÿá ÿ™ŸÜŸáÿß ÿ™ŸÜ ÿÆŸà€åÿ¥ ÿ¨Ÿà€åŸÖ ŸÜÿ®ÿ±ÿØ\n",
            "target ÿ≤ ŸÑÿ¥⁄©ÿ± ŸÜÿÆŸàÿßŸáŸÖ ⁄©ÿ≥€å ÿ±ŸÜÿ¨Ÿá ⁄©ÿ±ÿØ\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ŸÜÿÆÿ≥ÿ™ ÿ¢ŸÅÿ±€åŸÜ ⁄©ÿ±ÿØ ÿ®ÿ± ⁄©ÿ±ÿØ⁄Øÿßÿ±\n",
            "target ÿ¨ŸáÿßŸÜÿØÿßÿ± Ÿæ€åÿ±Ÿàÿ≤ Ÿà Ÿæÿ±Ÿàÿ±ÿØ⁄Øÿßÿ±\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ⁄ÜŸÜ€åŸÜ ÿØÿßÿØ Ÿæÿßÿ≥ÿÆ ⁄©Ÿá ÿßÿ≤ ÿ®€åÿ¥ ÿÆŸàÿ±ÿØ\n",
            "target ŸÖ⁄Øÿ± ÿ¢ÿ±ÿ≤Ÿà ÿ®ÿßÿ≤⁄Øÿ±ÿØÿØ ÿ®ÿØÿ±ÿØ\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ÿ®ÿØŸà ⁄ØŸÅÿ™ ÿ≤ÿßŸÑ ÿß€å Ÿæÿ≥ÿ± ÿß€åŸÜ ÿ≥ÿÆŸÜ\n",
            "target ŸÖ⁄ØŸà€å Ÿà ÿ¨ÿØÿß ⁄©ŸÜ ÿ≥ÿ±ÿ¥ ÿ±ÿß ÿ≤ ÿ®ŸÜ\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source ⁄ÜŸà ŸáŸÜ⁄ØÿßŸÖ ÿ±ŸÅÿ™ŸÜ ŸÅÿ±ÿßÿ≤ ÿ¢€åÿØÿ™\n",
            "target ÿ®Ÿá ÿØ€åÿØÿßÿ± ÿÆÿ≥ÿ±Ÿà ŸÜ€åÿßÿ≤ ÿ¢€åÿØÿ™\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n",
            "source €å⁄©€å ÿ®ÿ±⁄Øÿ≤€åŸÜÿØ ⁄©Ÿá ŸÜÿßŸÖ€å ÿ™ÿ±ÿ≥ÿ™\n",
            "target ÿ®Ÿá ÿÆÿßŸÇÿßŸÜ ⁄Ü€åŸÜ ÿ®ÿ±⁄Øÿ±ÿßŸÖ€å ÿ™ÿ±ÿ≥ÿ™\n",
            "predicted ⁄©Ÿá Ÿà Ÿà Ÿà PAD PAD PAD PAD PAD PAD PAD <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set correct path of GRU_logs in your system\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/HW4_Q1/LSTM_logs\""
      ],
      "metadata": {
        "id": "eiVI5TdorzSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wDahmgQGem9p",
        "FXUYdGpMFuCq",
        "BmnrWQT9FuCy",
        "zm6otv8sFuC_"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c64a6a50d9e4c41a5f1d7591700c859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1916a5d353a94dea80b79af06f33ce68",
              "IPY_MODEL_df3788559ea5425396b38dfa6e55c1e5",
              "IPY_MODEL_2390946e0905462894fb8c1959e42fe8"
            ],
            "layout": "IPY_MODEL_672277e98bee42e6b9c521307bb0060e"
          }
        },
        "1916a5d353a94dea80b79af06f33ce68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ebee065ee64ce68dfacd1eb122f997",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_314094a449444440bd65e2472b7425b3",
            "value": "Downloading builder script: "
          }
        },
        "df3788559ea5425396b38dfa6e55c1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06471efb792b4cf0b4605edc272142b4",
            "max": 2848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c55ffad6a8246aa97c10d4a4e9f0c9d",
            "value": 2848
          }
        },
        "2390946e0905462894fb8c1959e42fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8472e955bf74dc1a43e16ec64d006f3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bad9a9f9fc6f466b97c0bca94343ae77",
            "value": " 7.65k/? [00:00&lt;00:00, 392kB/s]"
          }
        },
        "672277e98bee42e6b9c521307bb0060e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ebee065ee64ce68dfacd1eb122f997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314094a449444440bd65e2472b7425b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06471efb792b4cf0b4605edc272142b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c55ffad6a8246aa97c10d4a4e9f0c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8472e955bf74dc1a43e16ec64d006f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad9a9f9fc6f466b97c0bca94343ae77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}